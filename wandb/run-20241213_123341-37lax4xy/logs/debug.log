2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Current SDK version is 0.17.4
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Configure stats pid to 1546325
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Loading settings from /home/yueyulin/.config/wandb/settings
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Loading settings from /home/yueyulin/github/RWKVinLLAMA/wandb/settings
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-12-13 12:33:41,946 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train_scripts/train_hybrid_deepspeed.py', 'program_abspath': '/home/yueyulin/github/RWKVinLLAMA/train_scripts/train_hybrid_deepspeed.py', 'program': '/home/yueyulin/github/RWKVinLLAMA/train_scripts/train_hybrid_deepspeed.py'}
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:_log_setup():529] Logging user logs to /home/yueyulin/github/RWKVinLLAMA/wandb/run-20241213_123341-37lax4xy/logs/debug.log
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:_log_setup():530] Logging internal logs to /home/yueyulin/github/RWKVinLLAMA/wandb/run-20241213_123341-37lax4xy/logs/debug-internal.log
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:init():569] calling init triggers
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:init():576] wandb.init called with sweep_config: {}
config: {'config_file': 'configs/qwen_0.5b.yaml', 'preprocessed_data': ['/home/yueyulin/data/all_train_ds_v1+magpie/'], 'output_dir': '/home/yueyulin/model/qwen_0.5b_full_layers_stage1', 'num_epochs': 1, 'max_seq_length': 512, 'num_devices': 4, 'dropout': 0.05, 'grad_cp': 1, 'save_per_batches': 10000, 'my_exit': 300, 'weight_decay': 0.1, 'lr_init': 0.0001, 'lr_final': 1e-05, 'beta1': 0.9, 'beta2': 0.95, 'layerwise_lr': 1, 'adam_eps': 1e-08, 'warmup_steps': 50, 'epoch_begin': 0, 'epoch_count': 150, 'epoch_save': 1, 'max_epochs': 2, 'check_val_every_n_epoch': 1, 'val_check_interval': 5000, 'num_sanity_val_steps': 0, 'log_every_n_steps': 5000, 'enable_checkpointing': False, 'accumulate_grad_batches': 4, 'gradient_clip_val': 1.0, 'num_nodes': 1, 'micro_bsz': 8, 'real_bsz': 128, 'my_pile_stage': 0, 'my_pile_edecay': 0, 'weight_decay_final': -1, 'proj_dir': None, 'eval_every_steps': 100, 'wandb': 'hybrid_trainer_toys', 'run_name': 'hybrid_trainer_toys', 'strategy': 'deepspeed_stage_2_offload', 'ds_bucket_mb': 200, 'my_qa_mask': 0, 'optim': 'adam', 'train_type': '', 'skip_steps': 0, 'full_params': True, 'ckpt_file': None, 'ckpt_dir': None, 'ckpt_id': None, 'deepspeed': True, 'deepspeed_config': None, 'deepspeed_stage': 3, 'deepspeed_offload': True, 'train_batch_size': 128, 'world_size': 4, 'local_rank': 0, 'stage': 1, 'max_trained_tokens': 400000000, 'terminate_at_loss': 0.01, 'my_pos_emb': 0, 'head_size_a': 64, 'head_size_divisor': 8, 'ctx_len': 4096, 'n_layer': 24, 'n_embd': 896, 'dim_att': 896, 'dim_ffn': 4864, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'vocab_size': 151936, 'layers': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], 'pad_id': 151645, 'betas': (0.9, 0.95), 'kl_weight': 1, 'ce_weight': 0, 'model_file': 'QWen2.5-0.5B', 'teacher_client_mode': False, 'is_hidden_align': False, 'is_sft': False, 'is_llama_ffn': True, 'is_rwkv_att_only': True, 'is_all_labels_kl': True, 'init_with_llama': False}
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:init():619] starting backend
2024-12-13 12:33:41,947 INFO    MainThread:1546325 [wandb_init.py:init():623] setting up manager
2024-12-13 12:33:41,949 INFO    MainThread:1546325 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-12-13 12:33:41,950 INFO    MainThread:1546325 [wandb_init.py:init():631] backend started and connected
2024-12-13 12:33:41,953 INFO    MainThread:1546325 [wandb_init.py:init():720] updated telemetry
2024-12-13 12:33:41,972 INFO    MainThread:1546325 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-12-13 12:33:43,018 INFO    MainThread:1546325 [wandb_run.py:_on_init():2402] communicating current version
2024-12-13 12:33:44,372 INFO    MainThread:1546325 [wandb_run.py:_on_init():2411] got version response upgrade_message: "wandb version 0.19.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2024-12-13 12:33:44,372 INFO    MainThread:1546325 [wandb_init.py:init():804] starting run threads in backend
2024-12-13 12:33:48,230 INFO    MainThread:1546325 [wandb_run.py:_console_start():2380] atexit reg
2024-12-13 12:33:48,230 INFO    MainThread:1546325 [wandb_run.py:_redirect():2235] redirect: wrap_raw
2024-12-13 12:33:48,230 INFO    MainThread:1546325 [wandb_run.py:_redirect():2300] Wrapping output streams.
2024-12-13 12:33:48,230 INFO    MainThread:1546325 [wandb_run.py:_redirect():2325] Redirects installed.
2024-12-13 12:33:48,231 INFO    MainThread:1546325 [wandb_init.py:init():847] run started, returning control to user process
