wandb_version: 1

config_file:
  desc: null
  value: configs/step_wise/test_hybrid_1_layer_qwenmlp-0.5B.yaml
preprocessed_data:
  desc: null
  value:
  - /home/yueyulin/data/IndustryInstruction_Qwen_0.5B_DS/
output_dir:
  desc: null
  value: /home/yueyulin/tmp/distill_qwen05b_1
num_epochs:
  desc: null
  value: 1
max_seq_length:
  desc: null
  value: 2048
num_devices:
  desc: null
  value: 4
dropout:
  desc: null
  value: 0.05
grad_cp:
  desc: null
  value: 1
save_per_batches:
  desc: null
  value: 10000
my_exit:
  desc: null
  value: 300
weight_decay:
  desc: null
  value: 0.1
lr_init:
  desc: null
  value: 0.0006
lr_final:
  desc: null
  value: 1.0e-05
beta1:
  desc: null
  value: 0.9
beta2:
  desc: null
  value: 0.95
layerwise_lr:
  desc: null
  value: 1
adam_eps:
  desc: null
  value: 1.0e-08
warmup_steps:
  desc: null
  value: 1000
epoch_begin:
  desc: null
  value: 0
epoch_count:
  desc: null
  value: 150
epoch_save:
  desc: null
  value: 1
max_epochs:
  desc: null
  value: 2
check_val_every_n_epoch:
  desc: null
  value: 1
val_check_interval:
  desc: null
  value: 5000
num_sanity_val_steps:
  desc: null
  value: 0
log_every_n_steps:
  desc: null
  value: 5000
enable_checkpointing:
  desc: null
  value: false
accumulate_grad_batches:
  desc: null
  value: 4
gradient_clip_val:
  desc: null
  value: 1.0
num_nodes:
  desc: null
  value: 1
micro_bsz:
  desc: null
  value: 2
real_bsz:
  desc: null
  value: 32
my_pile_stage:
  desc: null
  value: 0
my_pile_edecay:
  desc: null
  value: 0
weight_decay_final:
  desc: null
  value: -1
proj_dir:
  desc: null
  value: null
eval_every_steps:
  desc: null
  value: 100
wandb:
  desc: null
  value: hybrid_trainer
run_name:
  desc: null
  value: hybrid_trainer_4gpus_4090
strategy:
  desc: null
  value: deepspeed_stage_2_offload
ds_bucket_mb:
  desc: null
  value: 200
my_qa_mask:
  desc: null
  value: 0
optim:
  desc: null
  value: adam
train_type:
  desc: null
  value: ''
skip_steps:
  desc: null
  value: 0
ckpt_file:
  desc: null
  value: null
deepspeed:
  desc: null
  value: true
deepspeed_config:
  desc: null
  value: null
deepspeed_stage:
  desc: null
  value: 3
deepspeed_offload:
  desc: null
  value: false
my_pos_emb:
  desc: null
  value: 0
head_size_a:
  desc: null
  value: 64
head_size_divisor:
  desc: null
  value: 8
ctx_len:
  desc: null
  value: 4096
n_layer:
  desc: null
  value: 24
n_embd:
  desc: null
  value: 896
dim_att:
  desc: null
  value: 896
dim_ffn:
  desc: null
  value: 4864
pre_ffn:
  desc: null
  value: 0
head_qk:
  desc: null
  value: 0
tiny_att_dim:
  desc: null
  value: 0
tiny_att_layer:
  desc: null
  value: -999
vocab_size:
  desc: null
  value: 151936
layers:
  desc: null
  value:
  - 0
pad_id:
  desc: null
  value: 151645
betas:
  desc: null
  value:
  - 0.9
  - 0.95
kl_weight:
  desc: null
  value: 0.1
ce_weight:
  desc: null
  value: 1
model_file:
  desc: null
  value: Llama3.18BInstructRWKV8Layers
teacher_client_mode:
  desc: null
  value: false
nccl_file:
  desc: null
  value: nccl.txt
num_groups:
  desc: null
  value: 2
is_hidden_align:
  desc: null
  value: false
is_sft:
  desc: null
  value: false
is_llama_ffn:
  desc: null
  value: true
is_rwkv_att_only:
  desc: null
  value: false
is_all_labels_kl:
  desc: null
  value: true
_wandb:
  desc: null
  value:
    python_version: 3.12.4
    cli_version: 0.17.4
    framework: huggingface
    huggingface_version: 4.44.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1729860639
    t:
      1:
      - 1
      - 9
      - 11
      - 49
      - 51
      - 55
      - 71
      - 103
      - 105
      2:
      - 1
      - 9
      - 11
      - 49
      - 51
      - 55
      - 71
      - 103
      - 105
      3:
      - 13
      - 16
      - 23
      4: 3.12.4
      5: 0.17.4
      6: 4.44.2
      8:
      - 5
      13: linux-x86_64
