saving trainable to /data/rwkv/tmp/distill-en-zh-stage-2
2000 29.374891 5719435805926.4639  0, now saving...
save trainable parameters to /data/rwkv/tmp/distill-en-zh-stage-2/epoch_0_step_2000 pretrained from Llama3.18BInstructRWKV8Layers
save trainable parameters to /data/rwkv/tmp/distill-en-zh-stage-2/epoch_0_step_2000/Llama3.18BInstructRWKV8Layers.pth
/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/pytorch_lightning/strategies/deepspeed.py:634: When saving the DeepSpeed Stage 3 checkpoint, each worker will save a shard of the checkpoint within a directory. If a single file is required after training, see https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html#deepspeed-zero-stage-3-single-file for instructions.
saving trainable to /data/rwkv/tmp/distill-en-zh-stage-2
4000 29.097088 4332162084986.0303  0, now saving...
save trainable parameters to /data/rwkv/tmp/distill-en-zh-stage-2/epoch_0_step_4000 pretrained from Llama3.18BInstructRWKV8Layers
save trainable parameters to /data/rwkv/tmp/distill-en-zh-stage-2/epoch_0_step_4000/Llama3.18BInstructRWKV8Layers.pth








































































































































































































































































































































































































































































































































































































































































































