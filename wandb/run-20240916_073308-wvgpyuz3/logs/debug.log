2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Current SDK version is 0.17.6
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Configure stats pid to 510568
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Loading settings from /home/rwkv/.config/wandb/settings
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Loading settings from /home/rwkv/github/RWKVinLLAMA/wandb/settings
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train_scripts/train_hybrid.py', 'program_abspath': '/home/rwkv/github/RWKVinLLAMA/train_scripts/train_hybrid.py', 'program': '/home/rwkv/github/RWKVinLLAMA/train_scripts/train_hybrid.py'}
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:_log_setup():521] Logging user logs to /home/rwkv/github/RWKVinLLAMA/wandb/run-20240916_073308-wvgpyuz3/logs/debug.log
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:_log_setup():522] Logging internal logs to /home/rwkv/github/RWKVinLLAMA/wandb/run-20240916_073308-wvgpyuz3/logs/debug-internal.log
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:init():559] calling init triggers
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:init():566] wandb.init called with sweep_config: {}
config: {'config_file': 'configs/test_hybrid_full_logits_rwkv_att_only.yaml', 'train_data': None, 'c4_data': None, 'languages': ['en', 'zh'], 'train_datas': None, 'preprocessed_data': ['/data/rwkv/data/ultrachat_200k_ds_4k_sub_lengths/length__1536_1791'], 'output_dir': '/data/rwkv/tmp/distill_ultrachat_1536_1791', 'num_epochs': 1, 'max_seq_length': 1780, 'num_devices': 6, 'dropout': 0.01, 'grad_cp': 1, 'save_per_batches': 10000, 'my_exit': 300, 'weight_decay': 0.1, 'lr_init': 0.0001, 'lr_final': 0.0005, 'beta1': 0.9, 'beta2': 0.95, 'layerwise_lr': 1, 'adam_eps': 1e-08, 'warmup_steps': 200, 'epoch_begin': 0, 'epoch_count': 150, 'epoch_save': 1, 'max_epochs': 150, 'check_val_every_n_epoch': 1, 'val_check_interval': 5000, 'num_sanity_val_steps': 0, 'log_every_n_steps': 200, 'enable_checkpointing': False, 'accumulate_grad_batches': 1, 'gradient_clip_val': 1.0, 'num_nodes': 1, 'micro_bsz': 5, 'real_bsz': 30, 'my_pile_stage': 0, 'my_pile_edecay': 0, 'weight_decay_final': -1, 'proj_dir': None, 'eval_every_steps': 100, 'wandb': 'hybrid_trainer_1536_1791', 'run_name': 'hybrid_trainer_a800', 'strategy': 'deepspeed_stage_3_offload', 'ds_bucket_mb': 200, 'my_qa_mask': 0, 'optim': 'adam', 'train_type': '', 'skip_steps': 0, 'ckpt_file': '/data/rwkv/tmp/distill_ultrachat_1280_1535/ultrachat_1280_1535.pth', 'my_pos_emb': 0, 'head_size_a': 64, 'head_size_divisor': 8, 'ctx_len': 4096, 'n_layer': 32, 'n_embd': 4096, 'dim_att': 4096, 'dim_ffn': 14336, 'pre_ffn': 0, 'head_qk': 0, 'tiny_att_dim': 0, 'tiny_att_layer': -999, 'vocab_size': 128256, 'layers': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], 'pad_id': 128009, 'betas': (0.9, 0.95), 'kl_weight': 0.1, 'ce_weight': 1, 'model_file': 'Llama3.18BInstructRWKV8Layers', 'teacher_client_mode': True, 'nccl_file': 'nccl.txt', 'num_groups': 2, 'is_hidden_align': False, 'is_sft': False, 'is_llama_ffn': True, 'is_rwkv_att_only': True, 'my_timestamp': '2024-09-16 07:31:38', 'epoch_steps': 1077, 'world_size': 6, 'rank': 0, 'nccl_id': (45, 105, 91, 63, 39, 44, 28, -47, 2, 0, -60, 81, -84, 18, 18, 42, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, -25, 23, -16, 66, 127, 0, 0, 48, -39, -39, -89, -3, 127, 0, 0, -38, -99, -14, 100, 28, 33, -95, 19, 0, 1, 0, 0, 0, 0, 0, 0, 0, -107, -17, -123, 118, 59, 100, 84, 0, 0, 0, 0, 0, 0, 0, 0, 96, 43, -65, -101, 65, 127, 0, 0, 112, 78, -11, -17, 66, 127, 0, 0, 96, 43, -65, -101, 65, 127, 0, 0, 112, 78, -11, -17, 66, 127, 0, 0, -82, 64, -87, 0, 0, 0, 0, 0), 'server_rank': 3}
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:init():609] starting backend
2024-09-16 07:33:08,598 INFO    MainThread:510568 [wandb_init.py:init():613] setting up manager
2024-09-16 07:33:08,599 INFO    MainThread:510568 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-09-16 07:33:08,600 INFO    MainThread:510568 [wandb_init.py:init():621] backend started and connected
2024-09-16 07:33:08,623 INFO    MainThread:510568 [wandb_init.py:init():716] updated telemetry
2024-09-16 07:33:08,627 INFO    MainThread:510568 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2024-09-16 07:33:09,856 WARNING MainThread:510568 [wandb_init.py:init():1181] interrupted
Traceback (most recent call last):
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_init.py", line 1177, in init
    return wi.init()
           ^^^^^^^^^
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_init.py", line 796, in init
    run._set_run_obj(run_result.run)
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 1571, in _set_run_obj
    if self.settings._offline:
       ^^^^^^^^^^^^^
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 391, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 932, in settings
    cp = self._settings.copy()
         ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_settings.py", line 1449, in copy
    return self.__copy__()
           ^^^^^^^^^^^^^^^
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_settings.py", line 1423, in __copy__
    new.update({k: v._value}, source=v.source)
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_settings.py", line 1510, in update
    self.__dict__[key].update(value, source)
  File "/home/rwkv/anaconda3/envs/torch_env/lib/python3.11/site-packages/wandb/sdk/wandb_settings.py", line 576, in update
    def update(self, value: Any, source: int = Source.OVERRIDE) -> None:
    
KeyboardInterrupt
